# Creative Applications of Deep Learning with TensorFlow

This repository contains assignments for the Kadenze Course: Creative Applications of Deep Learning with TensorFlow I

Session 1: Introduction to Tensorflow  
- Teaches how to preprocess your data and apply convolution to different kernels  
- Dataset used for this session was from Caltech 101  

Session 2: Training a Network w/ Tensorflow
- Teaches how to create a deep neural network  
- Discusses the different parameters in Tensorflow (ex. Optimizations, Cost Functions, Activation Functions, etc.)  
- Apply creative thinking in using neural networks in images
- Dataset used for this session was from Caltech 101  

Session 3: Unsupervised and Supervised Learning
- Teaches how to build an autoencoder
- Discusses how to create an audio classification task with softmax and one-hot encoding
- Datasets used for this session: Caltech 101 and Stanford Dogs 

Session 4: Visualizing Representations 
- Teaches how to build a style transfer model
- Enables visualization of gradients
- Apply Deep Dream to chosen images 

Session 5: Generative Adversarial Networks and Recurrent Neural Networks 
- Teaches how to use GANs for image processing and RNNs for text processing 
- Discusses how to apply VAE to GAN 
- Shows how to use pre-trained models 

Project  
- Audio Style Transfer  
- Image Style Transfer using VGG Face Model  

 ## References
 [1] <a href="https://www.kadenze.com/courses/creative-applications-of-deep-learning-with-tensorflow/info">Creative Applications of Deep Learning w/ TensorFlow</a>.  
 [2] L. Fei-Fei, R. Fergus and P. Perona. Learning generative visual models from few training examples: an incremental Bayesian approach tested on 101 object categories. IEEE. CVPR 2004, Workshop on Generative-Model Based Vision. 2004.  
 [3] Aditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao and Li Fei-Fei. Novel dataset for Fine-Grained Image Categorization. First Workshop on Fine-Grained Visual Categorization (FGVC), IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2011.  
 [4] D. Ulyanov and V. Lebedev. (2016, December 13). Audio texture synthesis and style transfer. [Blog post]. Retrieved from https://dmitryulyanov.github.io/audio-texture-synthesis-and-style-transfer/  
